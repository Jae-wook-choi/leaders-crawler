import requests
from bs4 import BeautifulSoup
import pandas as pd
import streamlit as st

def scrape_news(start_page: int, end_page: int) -> pd.DataFrame:
    base_url = "https://finance.naver.com/news/mainnews.naver?page="
    news_list = []

    for page_num in range(start_page, end_page + 1):
        url = base_url + str(page_num)
        response = requests.get(url)
        response.encoding = 'euc-kr'  # ë„¤ì´ë²„ ë‰´ìŠ¤ í˜ì´ì§€ ì¸ì½”ë”©
        soup = BeautifulSoup(response.text, 'html.parser')

        for item in soup.select("ul.mainNewsList li"):
            a_tag = item.find("a")
            date_tag = item.select_one("span.wdate")

            if a_tag and date_tag:
                title = a_tag.text.strip()
                link = "https://finance.naver.com" + a_tag.get("href")
                date = date_tag.text.strip()

                news_list.append({
                    "title": title,
                    "link": link,
                    "date": date
                })

    return pd.DataFrame(news_list)

st.set_page_config(page_title="ë‰´ìŠ¤ í¬ë¡¤ëŸ¬", layout="wide")
st.title("ğŸ“ˆ ê¸ˆìœµ ë‰´ìŠ¤ í¬ë¡¤ëŸ¬")

start_page = st.number_input("ì‹œì‘ í˜ì´ì§€", min_value=1, max_value=100, value=1)
end_page = st.number_input("ë í˜ì´ì§€", min_value=1, max_value=100, value=1)

if st.button("í¬ë¡¤ë§ ì‹œì‘"):
    with st.spinner("í¬ë¡¤ë§ ì¤‘ì…ë‹ˆë‹¤..."):
        df = scrape_news(start_page, end_page)
        if not df.empty:
            st.success(f"{len(df)}ê°œì˜ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
            st.dataframe(df)
        else:
            st.warning("ë‰´ìŠ¤ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í˜ì´ì§€ ë²”ìœ„ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")